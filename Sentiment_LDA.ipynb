{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBdbBaeNeSeWa5yQEf1Vzg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rotem2411/alephBERTgimmelDalet/blob/main/Sentiment_LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YrscUhc4RI_T"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from string import punctuation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_csv_file(file_path):\n",
        "    data = []\n",
        "    with open(file_path, 'r', newline='', encoding='utf-8') as csvfile:\n",
        "        csv_reader = csv.reader(csvfile)\n",
        "        for row in csv_reader:\n",
        "            data.append(row)\n",
        "    return data"
      ],
      "metadata": {
        "id": "K8ZPx8juRlVP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    file_path = 'sentiments.csv'\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(df.head(10))\n",
        "\n",
        "    # Total number of samples\n",
        "    num_samples = len(df)\n",
        "    print(\"Total number of samples:\", num_samples)\n",
        "\n",
        "    # Sentiment distribution\n",
        "    Sentiment_distribution = {}\n",
        "    for index, row in df.iterrows():\n",
        "        Sentiment_label = row['tag']\n",
        "        if Sentiment_label not in Sentiment_distribution:\n",
        "            Sentiment_distribution[Sentiment_label] = 1\n",
        "        else:\n",
        "            Sentiment_distribution[Sentiment_label] += 1\n",
        "    print(\"Sentiment Distribution:\")\n",
        "    for Sentiment_label, count in Sentiment_distribution.items():\n",
        "        print(f\"{Sentiment_label}: {count} tags\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIWzcPBPRtoP",
        "outputId": "da0eff29-2780-4f17-e14c-5e341ecc0557"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                               text tag category class  \\\n",
            "0   1                    האריות של הצל חזק פה בתגובות...   ש  ECONOMY    b1   \n",
            "1   2  זמרת תעשייה רק מפרסומות מפורסמת\\n  אבל אין קהל...   ש  ECONOMY    b1   \n",
            "2   4  את לא יורקת לבאר שממנה שתית. יפה יפה, אבל חסרת...   ש  ECONOMY    b1   \n",
            "3   5  שמעון\\n  משתתף בפרסומת למילקי במקום לעורר מודע...   ש  ECONOMY    b1   \n",
            "4   6  הצחקתם אותי\\n  מה כל כך אמייזינג בחברה עם אפס ...   ש  ECONOMY    b1   \n",
            "5   7  איסו חברת הייטק מצליחה צריכה פרסומות שיבואו לע...   ש  ECONOMY    b1   \n",
            "6   8           לא מכיר אותה ולא שמעתי אפילו שיר אחד שלה   ש  ECONOMY    b1   \n",
            "7   9  וואללה לא יודע מה מתלהבים מנגה ארז. זה בכלל לא...   ש  ECONOMY    b1   \n",
            "8  10  אהובה שגיא\\n  נגה גדולה.זמרת מעולה.פרסומת מדלי...   ח  ECONOMY    b1   \n",
            "9  11  הפרסומת של אמדוקס נראית מאוד קודרת ואפורה, כמו...   ש  ECONOMY    b1   \n",
            "\n",
            "   total_tags  selected_tag  polarity  \n",
            "0           2             2       1.0  \n",
            "1           2             2       1.0  \n",
            "2           2             2       1.0  \n",
            "3           2             2       1.0  \n",
            "4           2             2       1.0  \n",
            "5           2             2       1.0  \n",
            "6           2             2       1.0  \n",
            "7           2             2       1.0  \n",
            "8           2             2       1.0  \n",
            "9           2             2       1.0  \n",
            "Total number of samples: 75151\n",
            "Sentiment Distribution:\n",
            "ש: 60841 tags\n",
            "ח: 6982 tags\n",
            "נ: 7328 tags\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = df['text']\n",
        "labels = df['tag']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features,labels,test_size = 0.2, random_state=42)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X_train,y_train,test_size = 0.5, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test,y_test,test_size = 0.5, random_state=42)\n",
        "\n",
        "print(\"Data distribution:\\n- Train: {} \\n- Validation: {} \\n- Test: {}\".format(len(y_train),len(y_val),len(y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFGI51fVkaFf",
        "outputId": "f18ec47f-e651-4137-c468-887594a45db5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data distribution:\n",
            "- Train: 60120 \n",
            "- Validation: 7515 \n",
            "- Test: 7516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanwords(text):\n",
        "    wn = nltk.WordNetLemmatizer()\n",
        "    stopword = nltk.corpus.stopwords.words('hebrew')\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    lower = [word.lower() for word in tokens]\n",
        "    no_stopwords = [word for word in lower if word not in stopword]\n",
        "    no_alpha = [word for word in no_stopwords if word.isalpha()]\n",
        "    lemm_text = [wn.lemmatize(word) for word in no_alpha]\n",
        "    clean_text = lemm_text\n",
        "    return clean_text"
      ],
      "metadata": {
        "id": "mC5JkMWFCX5C"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vect = TfidfVectorizer(analyzer=cleanwords)\n",
        "tfidf_vect_fit=tfidf_vect.fit(X_train)"
      ],
      "metadata": {
        "id": "6Na-qs0OdU4A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(data, tfidf_vect_fit):\n",
        "    X_tfidf = tfidf_vect_fit.transform(data)\n",
        "    words = tfidf_vect_fit.get_feature_names_out()\n",
        "    X_tfidf_df = pd.DataFrame(X_tfidf.toarray())\n",
        "    X_tfidf_df.columns = words\n",
        "    return(X_tfidf_df)"
      ],
      "metadata": {
        "id": "kk-Apm3K--Gv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = vectorize(X_train, tfidf_vect_fit)"
      ],
      "metadata": {
        "id": "weLzkKSSGXsn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDA - Latent Dirichlet allocation"
      ],
      "metadata": {
        "id": "0WfW-hsXqBMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix = tfidf_vect.fit_transform(X_train)\n",
        "num_topics = 3\n",
        "lda_model = LatentDirichletAllocation(n_components=num_topics, random_state=100)\n",
        "lda_matrix = lda_model.fit_transform(tfidf_matrix)"
      ],
      "metadata": {
        "id": "OwDiuPpcTXt9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the top words for each topic\n",
        "feature_names = tfidf_vect.get_feature_names_out()\n",
        "for topic_idx, topic in enumerate(lda_model.components_):\n",
        "    top_words = [feature_names[i] for i in topic.argsort()[:-11:-1]]\n",
        "    print(f\"Topic {topic_idx + 1}: {', '.join(top_words)}\")"
      ],
      "metadata": {
        "id": "X0byaz8BPv3q",
        "outputId": "53523c60-abb6-45e4-a4ed-bcfdd1435258",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 1: עויין, שבחירות, ואופא, שמחקו, עורכת, קצורי, ללמידה, מאפילה, קוק, ומסתיים\n",
            "Topic 2: חינמית, ובמשבר, יורדות, צברתי, החזיק, הטכנולוגייה, מנובלים, התייעלו, מקדשת, כלום\n",
            "Topic 3: מיעוטם, במעטפות, משתמשיים, לאחד, שמספר, שמיובאים, מתחסנות, בטיחותית, הסמטלנים, והחברים\n"
          ]
        }
      ]
    }
  ]
}